{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuYXoEYHSPK3VX6a3APNs9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SashaNasonova/burnSeverity/blob/main/BurnSeverityMapping_ImageAvailability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for available imagery."
      ],
      "metadata": {
        "id": "a7fvXjb6LSn2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4RJK0qJLOQQ"
      },
      "outputs": [],
      "source": [
        "# Clone github repository to be able to access the test data and provincial extent vector data\n",
        "!git clone https://github.com/SashaNasonova/burnSeverity.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the libraries\n",
        "%pip install geemap==0.32.1 #Stable version is (0.32.1) from 15-Jul-2024\n",
        "%pip install pycrs rasterio python-pptx cartopy requests"
      ],
      "metadata": {
        "id": "5VERCksbLdia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "import ee\n",
        "import geemap\n",
        "import os, json, shutil\n",
        "import geopandas\n",
        "from osgeo import gdal\n",
        "from google.colab import files\n",
        "import requests, zipfile\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "-YLtSQffLe5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aoionly(img):\n",
        "  return(img.updateMask(poly_mask))\n",
        "\n",
        "def getfiles(d,ext):\n",
        "    paths = []\n",
        "    for file in os.listdir(d):\n",
        "        if file.endswith(ext):\n",
        "            paths.append(os.path.join(d, file))\n",
        "    return(paths)\n",
        "\n",
        "#Helper function must be nested within barc\n",
        "\n",
        "def getDate(im):\n",
        "    return(ee.Image(im).date().format(\"YYYY-MM-dd\"))\n",
        "\n",
        "def getSceneIds(im):\n",
        "    return(ee.Image(im).get('PRODUCT_ID'))\n",
        "\n",
        "def mosaicByDate(indate):\n",
        "    d = ee.Date(indate)\n",
        "    #print(d)\n",
        "    im = col.filterBounds(poly).filterDate(d, d.advance(1, \"day\")).mosaic()\n",
        "    #print(im)\n",
        "    return(im.set(\"system:time_start\", d.millis(), \"system:index\", d.format(\"YYYY-MM-dd\")))\n",
        "\n",
        "def runDateMosaic(col_list):\n",
        "    #get a list of unique dates within the list\n",
        "    date_list = col_list.map(getDate).getInfo()\n",
        "    udates = list(set(date_list))\n",
        "    udates.sort()\n",
        "    udates_ee = ee.List(udates)\n",
        "\n",
        "    #mosaic images by unique date\n",
        "    mosaic_imlist = udates_ee.map(mosaicByDate)\n",
        "    return(ee.ImageCollection(mosaic_imlist))\n",
        "\n",
        "#Landsat cloud mask from metadata\n",
        "## Check this!!!\n",
        "def get_cloud(img1):\n",
        "    ### Change as of Oct 24, 2023: cloud shadow is too inaccurate, remove\n",
        "    ### Though it is picking up topographic shadow. Questions!\n",
        "    # Bits 3 and 4 are cloud and cloud shadow, respectively.\n",
        "    #cloudShadowBitMask = (1 << 4)\n",
        "    cloudBitMask = (1 << 3)\n",
        "    # Get the pixel QA band.\n",
        "    qa = img1.select('QA_PIXEL')\n",
        "    #set both flags to 1\n",
        "    #clouds = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cloudShadowBitMask).eq(0)).rename('cloudmsk')\n",
        "    clouds = qa.bitwiseAnd(cloudBitMask).eq(0).rename('cloudmsk')\n",
        "    return(img1.addBands(clouds))"
      ],
      "metadata": {
        "id": "1t5KalKSa2sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Authenticate gee\n",
        "ee.Authenticate()"
      ],
      "metadata": {
        "id": "gvDeGq9rVSsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize with a google cloud project\n",
        "project = 'wlbr-2025'\n",
        "ee.Initialize(project=project)"
      ],
      "metadata": {
        "id": "V1Z8xW_fVWS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get fire perimeter file (either user defined) or pull from BC Wildfire\n",
        "# Open fires shapefile if exists\n",
        "fires_shp = '/content/perims.shp'\n",
        "if os.path.exists(fires_shp):\n",
        "  print('Using user specified perimeter file')\n",
        "else:\n",
        "  print('Downloading BC Wildfire current fire perimeter file')\n",
        "  fires_shp = '/content/prot_current_fire_polys/prot_current_fire_polys.shp'\n",
        "\n",
        "  url = 'https://pub.data.gov.bc.ca/datasets/cdfc2d7b-c046-4bf0-90ac-4897232619e1/prot_current_fire_polys.zip'\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "      with open(\"prot_current_fire_poly.zip\", 'wb') as file:\n",
        "          file.write(response.content)\n",
        "      print(\"File downloaded successfully\")\n",
        "  else:\n",
        "      print(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "\n",
        "  with zipfile.ZipFile(\"prot_current_fire_poly.zip\", 'r') as zip_ref:\n",
        "      zip_ref.extractall('/content/prot_current_fire_polys')\n",
        "  print('Fire perimeter file: ',fires_shp)"
      ],
      "metadata": {
        "id": "kQAR7Z8ISQK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "# Visualize in table format\n",
        "fires = geemap.shp_to_ee(fires_shp)\n",
        "fires_df = geopandas.read_file(fires_shp)\n",
        "fires_df_tbl = fires_df.drop(columns=['geometry'], axis=1, inplace=False)\n",
        "fires_df_tbl = fires_df_tbl[(fires_df_tbl['FIRE_STAT']=='Out') & (fires_df_tbl['FIRE_SZ_HA']>=100)] #uncomment for fires that are out and >= 100 ha\n",
        "fires_df_tbl"
      ],
      "metadata": {
        "id": "4NNoj-NTVlzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select fire perimeter list\n",
        "firenumber = 'G70422'"
      ],
      "metadata": {
        "id": "uWZ-LGswTEHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now select one fire (in the test data, there's only one fire perimeter)\n",
        "fieldname = 'FIRE_NUM' #unique firenumber field, change if needed\n",
        "\n",
        "# First check if the firenumber exists in the shapefile provided\n",
        "firelist = fires_df[fieldname].tolist()\n",
        "\n",
        "if firenumber not in firelist:\n",
        "  print('Selected fire number:',firenumber)\n",
        "  print('Available fire numbers: ',firelist)\n",
        "  raise ValueError('Fire number not in fire list. Typo?')\n",
        "\n",
        "# Create output folder\n",
        "outfolder = 'scene_availability_eval_'+ datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "if not os.path.exists(outfolder):\n",
        "  os.mkdir(outfolder)\n",
        "\n",
        "# Save a copy of the fire perimeter\n",
        "vector_folder = os.path.join(outfolder,'vectors')\n",
        "if not os.path.exists(vector_folder):\n",
        "  os.mkdir(vector_folder)\n",
        "\n",
        "outshp = os.path.join(vector_folder,firenumber+'.shp')\n",
        "fires_df_sub = fires_df[fires_df[fieldname]==firenumber]\n",
        "fires_df_sub.to_file(outshp,driver='ESRI Shapefile')\n",
        "\n",
        "# Load in the single perimeter\n",
        "poly = geemap.shp_to_ee(outshp)\n",
        "\n",
        "# Create raster mask to reduce extent of image collections\n",
        "# Function aoionly in functions\n",
        "poly_buf = poly.geometry().buffer(500).bounds()\n",
        "poly_mask = ee.Image.constant(1).clip(poly_buf).selfMask()"
      ],
      "metadata": {
        "id": "YekvDfH_cDTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define collections\n",
        "dattype_info = {\n",
        "    'S2': {\n",
        "        'collection_id': 'COPERNICUS/S2_SR_HARMONIZED',\n",
        "        'cld_field': 'CLOUDY_PIXEL_PERCENTAGE',\n",
        "        'bands': ['B2','B3','B4','MSK_CLDPRB','AOT']\n",
        "    },\n",
        "    'L9': {\n",
        "        'collection_id': 'LANDSAT/LC09/C02/T1_L2',\n",
        "        'cld_field': 'CLOUD_COVER',\n",
        "        'bands':['SR_B2','SR_B3','SR_B4','QA_PIXEL']\n",
        "    },\n",
        "    'L8': {\n",
        "        'collection_id': 'LANDSAT/LC08/C02/T1_L2',\n",
        "        'cld_field': 'CLOUD_COVER',\n",
        "        'bands':['SR_B2','SR_B3','SR_B4','QA_PIXEL']\n",
        "    },\n",
        "    'L8_TOA': {\n",
        "        'collection_id': 'LANDSAT/LC08/C02/T1_TOA',\n",
        "        'cld_field': 'CLOUD_COVER',\n",
        "        'bands':['B2','B3','B4','QA_PIXEL']\n",
        "    },\n",
        "    'L9_TOA': {\n",
        "        'collection_id': 'LANDSAT/LC09/C02/T1_TOA',\n",
        "        'cld_field': 'CLOUD_COVER',\n",
        "        'bands':['B2','B3','B4','QA_PIXEL']\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "95UYaotVY4SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select which we want to assess\n",
        "dattypes = ['S2','L8','L9']"
      ],
      "metadata": {
        "id": "ZyB-scAfqVV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assess pre-fire image availability\n",
        "startdate_pre = '2024-07-01'\n",
        "enddate_pre = '2024-09-01'\n",
        "cld = 20\n",
        "\n",
        "df_list = []\n",
        "\n",
        "print('Assessing pre-fire image availability for',firenumber)\n",
        "for dattype in dattypes:\n",
        "  print('Checking ',dattype)\n",
        "  col = ee.ImageCollection(dattype_info[dattype]['collection_id']).map(aoionly).select(dattype_info[dattype]['bands'])\n",
        "  cld_field = dattype_info[dattype]['cld_field']\n",
        "  before = col.filterDate(startdate_pre,enddate_pre).filterBounds(poly).filter(ee.Filter.lt(cld_field,cld))\n",
        "  before_list = before.toList(10000)\n",
        "\n",
        "  if before_list.size() == 0:\n",
        "      print('Zero scenes were found for ',dattype)\n",
        "\n",
        "  # Create before mosaics\n",
        "  pre_mosaic_col = runDateMosaic(before_list)\n",
        "\n",
        "  # Ask server for individual scene metadata\n",
        "  metadata = before.getInfo()\n",
        "\n",
        "  # Turn metadata into table format\n",
        "  features = metadata['features']\n",
        "\n",
        "  out = []\n",
        "  for i in features:\n",
        "      d1 = pd.DataFrame([{'id':i['id']}])\n",
        "      p1 = pd.DataFrame([i['properties']])\n",
        "      t1 = d1.join(p1)\n",
        "      out.append(t1)\n",
        "\n",
        "  meta_df = pd.concat(out)\n",
        "\n",
        "  def strDate(string):\n",
        "      u_str = string.rsplit('_')[1].rsplit('T')[0]\n",
        "      s = u_str[0:4] + '-' + u_str[4:6] + '-' + u_str[6:8]\n",
        "      return(s)\n",
        "\n",
        "  #add date column\n",
        "  if dattype.startswith('S2'):\n",
        "      meta_df['date'] = meta_df['DATATAKE_IDENTIFIER'].apply(strDate)\n",
        "  else:\n",
        "      meta_df['date'] = meta_df['DATE_ACQUIRED']\n",
        "\n",
        "  #outpath = os.path.join(outfolder,firenumber+'_'+dattype+'_pre_sceneMetadata.csv')\n",
        "  #meta_df.to_csv(outpath)\n",
        "\n",
        "  #make a copy of meta_df\n",
        "  pre_meta_scenes = meta_df.copy()\n",
        "\n",
        "  # Classify to get coverage and cloud extent, fix this to check if any bands are equal to 0\n",
        "  def classify_extent(img1):\n",
        "      if dattype.startswith('S2'):\n",
        "          classes = img1.expression(\"((B2 + B3 + B4) !=0) ? 1 \"\n",
        "                                      \": 0\",{'B2': img1.select('B2'),\n",
        "                                            'B3': img1.select('B3'),\n",
        "                                            'B4': img1.select('B4')}).rename('c').clip(poly)\n",
        "      else:\n",
        "          classes = img1.expression(\"((B2 + B3 + B4) !=0) ? 1 \"\n",
        "                                      \": 0\",{'B2': img1.select('SR_B2'),\n",
        "                                            'B3': img1.select('SR_B3'),\n",
        "                                            'B4': img1.select('SR_B4')}).rename('c').clip(poly)\n",
        "      return(classes)\n",
        "\n",
        "  pre_mosaic_extent = pre_mosaic_col.map(classify_extent).toBands()\n",
        "\n",
        "  def classify_cc(img1):\n",
        "      if dattype.startswith('S2'):\n",
        "          classes = img1.expression(\"(MSK_CLDPRB > 30) ? 1 \"\n",
        "                              \": 0\",{'MSK_CLDPRB': img1.select('MSK_CLDPRB')}).rename('c').clip(poly)\n",
        "      else:\n",
        "          classes = img1.expression(\"(cloudmsk == 1) ? 0 \"\n",
        "                              \": 1\",{'cloudmsk': img1.select('cloudmsk')}).rename('c').clip(poly)\n",
        "      return(classes)\n",
        "\n",
        "  if dattype.startswith('S2'):\n",
        "      pre_mosaic_cc = pre_mosaic_col.map(classify_cc).toBands()\n",
        "      aot = pre_mosaic_col.select('AOT').toBands().divide(1000)\n",
        "      reduced_mean_aot = aot.reduceRegion(reducer=ee.Reducer.mean(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "  else:\n",
        "      pre_mosaic_cloudmsk = pre_mosaic_col.map(get_cloud)\n",
        "      pre_mosaic_cc = pre_mosaic_cloudmsk.map(classify_cc).toBands()\n",
        "\n",
        "  #Calculate statistics, if the image is too big this may fail.\n",
        "  #This step causes problems sometimes due to maxPixels limits\n",
        "  reduced_sum = pre_mosaic_extent.reduceRegion(reducer=ee.Reducer.sum(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "  reduced_count = pre_mosaic_extent.reduceRegion(reducer=ee.Reducer.count(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "\n",
        "  reduced_sum_cc = pre_mosaic_cc.reduceRegion(reducer=ee.Reducer.sum(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "  reduced_count_cc = pre_mosaic_cc.reduceRegion(reducer=ee.Reducer.count(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "\n",
        "  print('Image statistics calculated')\n",
        "\n",
        "  #Rearrange and calculate percent coverage and percent cloud cover\n",
        "  #extent\n",
        "  df_sum = pd.DataFrame([reduced_sum]).T\n",
        "  df_sum.columns = ['sum']\n",
        "\n",
        "  df_count = pd.DataFrame([reduced_count]).T\n",
        "  df_count.columns = ['count']\n",
        "\n",
        "  df_perc = df_sum.join(df_count)\n",
        "  df_perc['percent_coverage'] = (df_perc['sum']/df_perc['count'])*100\n",
        "\n",
        "  #cloud cover\n",
        "  df_sum_cc = pd.DataFrame([reduced_sum_cc]).T\n",
        "  df_sum_cc.columns = ['sum_cc']\n",
        "\n",
        "  df_count_cc = pd.DataFrame([reduced_count_cc]).T\n",
        "  df_count_cc.columns = ['count_cc']\n",
        "\n",
        "  df_perc_cc = df_sum_cc.join(df_count_cc)\n",
        "  df_perc_cc['percent_cc'] = (df_perc_cc['sum_cc']/df_perc_cc['count_cc'])*100\n",
        "  #print(df_perc_cc)\n",
        "\n",
        "  if dattype.startswith('S'):\n",
        "      #aot\n",
        "      df_mean_aot = pd.DataFrame([reduced_mean_aot]).T\n",
        "      df_mean_aot.columns = ['mean_aot']\n",
        "\n",
        "      #join extent and cc\n",
        "      meta_df_ext_temp = df_perc.join(df_perc_cc)\n",
        "\n",
        "      #get rid of cc suffix\n",
        "      oldnames = meta_df_ext_temp.index\n",
        "      newnames = [s.rsplit('_')[0] for s in oldnames]\n",
        "      meta_df_ext_temp.index = newnames\n",
        "\n",
        "      #get rid of aot suffix\n",
        "      oldnames = df_mean_aot.index\n",
        "      newnames = [s.rsplit('_')[0] for s in oldnames]\n",
        "      df_mean_aot.index = newnames\n",
        "\n",
        "      meta_df_ext = meta_df_ext_temp.join(df_mean_aot)\n",
        "      #print(meta_df_ext)\n",
        "\n",
        "  else:\n",
        "      #join extent and cc\n",
        "      meta_df_ext = df_perc.join(df_perc_cc)\n",
        "\n",
        "      #get rid of cc suffix\n",
        "      oldnames = meta_df_ext.index\n",
        "      newnames = [s.rsplit('_')[0] for s in oldnames]\n",
        "      meta_df_ext.index = newnames\n",
        "\n",
        "  #get average scene cloud cover and join to mosaic metadata\n",
        "  pre_meta_scenes_cld = pre_meta_scenes.groupby('date')[cld_field].mean()\n",
        "  temp = pd.DataFrame(pre_meta_scenes_cld)\n",
        "  pre_meta_scenes_cld = temp.rename(columns={'date':'date',cld_field:'percent_cc_scene'})\n",
        "\n",
        "  meta_df_ext = meta_df_ext.join(pre_meta_scenes_cld)\n",
        "  meta_df_ext_out = meta_df_ext.copy().round(2).drop(columns=['sum','count','sum_cc','count_cc'])\n",
        "  meta_df_ext_out['sensor'] = dattype\n",
        "\n",
        "  if 'mean_aot' not in meta_df_ext_out.columns:\n",
        "    meta_df_ext_out['mean_aot'] = None\n",
        "\n",
        "  outpath = os.path.join(outfolder,firenumber+'_'+dattype+'_pre_mosaicMetadata.csv')\n",
        "  meta_df_ext_out.to_csv(outpath)\n",
        "  df_list.append(meta_df_ext_out)\n",
        "  print('Dataframe prepared')\n",
        "\n",
        "#Output final pre-fire dataframe and save\n",
        "pre_df = pd.concat(df_list)\n",
        "outpath2 = os.path.join(outfolder,firenumber+'_all_pre_mosaicMetadata.csv')\n",
        "pre_df.to_csv(outpath2)"
      ],
      "metadata": {
        "id": "Ebdo9B-NTIyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize pre-fire image availability\n",
        "pre_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jgurjlFceizB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assess post-fire image availability\n",
        "startdate_post = '2025-07-15'\n",
        "enddate_post = '2025-10-01'\n",
        "cld = 100\n",
        "\n",
        "df_list = []\n",
        "\n",
        "print('Assessing post-fire image availability for',firenumber)\n",
        "for dattype in dattypes:\n",
        "  print('Checking ',dattype)\n",
        "  col = ee.ImageCollection(dattype_info[dattype]['collection_id']).map(aoionly).select(dattype_info[dattype]['bands'])\n",
        "  cld_field = dattype_info[dattype]['cld_field']\n",
        "  after = col.filterDate(startdate_post,enddate_post).filterBounds(poly).filter(ee.Filter.lt(cld_field,cld))\n",
        "  after_list = after.toList(10000)\n",
        "\n",
        "  if after_list.size() == 0:\n",
        "      print('Zero scenes were found for ',dattype)\n",
        "\n",
        "  # Create after mosaics\n",
        "  post_mosaic_col = runDateMosaic(after_list)\n",
        "\n",
        "  # Ask server for individual scene metadata\n",
        "  metadata = after.getInfo()\n",
        "\n",
        "  # Turn metadata into table format\n",
        "  features = metadata['features']\n",
        "\n",
        "  out = []\n",
        "  for i in features:\n",
        "      d1 = pd.DataFrame([{'id':i['id']}])\n",
        "      p1 = pd.DataFrame([i['properties']])\n",
        "      t1 = d1.join(p1)\n",
        "      out.append(t1)\n",
        "\n",
        "  meta_df = pd.concat(out)\n",
        "\n",
        "  def strDate(string):\n",
        "      u_str = string.rsplit('_')[1].rsplit('T')[0]\n",
        "      s = u_str[0:4] + '-' + u_str[4:6] + '-' + u_str[6:8]\n",
        "      return(s)\n",
        "\n",
        "  #add date column\n",
        "  if dattype.startswith('S2'):\n",
        "      meta_df['date'] = meta_df['DATATAKE_IDENTIFIER'].apply(strDate)\n",
        "  else:\n",
        "      meta_df['date'] = meta_df['DATE_ACQUIRED']\n",
        "\n",
        "  #outpath = os.path.join(outfolder,firenumber+'_'+dattype+'_pre_sceneMetadata.csv')\n",
        "  #meta_df.to_csv(outpath)\n",
        "\n",
        "  #make a copy of meta_df\n",
        "  post_meta_scenes = meta_df.copy()\n",
        "\n",
        "  # Classify to get coverage and cloud extent, fix this to check if any bands are equal to 0\n",
        "  def classify_extent(img1):\n",
        "      if dattype.startswith('S2'):\n",
        "          classes = img1.expression(\"((B2 + B3 + B4) !=0) ? 1 \"\n",
        "                                      \": 0\",{'B2': img1.select('B2'),\n",
        "                                            'B3': img1.select('B3'),\n",
        "                                            'B4': img1.select('B4')}).rename('c').clip(poly)\n",
        "      else:\n",
        "          classes = img1.expression(\"((B2 + B3 + B4) !=0) ? 1 \"\n",
        "                                      \": 0\",{'B2': img1.select('SR_B2'),\n",
        "                                            'B3': img1.select('SR_B3'),\n",
        "                                            'B4': img1.select('SR_B4')}).rename('c').clip(poly)\n",
        "      return(classes)\n",
        "\n",
        "  post_mosaic_extent = post_mosaic_col.map(classify_extent).toBands()\n",
        "\n",
        "  def classify_cc(img1):\n",
        "      if dattype.startswith('S2'):\n",
        "          classes = img1.expression(\"(MSK_CLDPRB > 30) ? 1 \"\n",
        "                              \": 0\",{'MSK_CLDPRB': img1.select('MSK_CLDPRB')}).rename('c').clip(poly)\n",
        "      else:\n",
        "          classes = img1.expression(\"(cloudmsk == 1) ? 0 \"\n",
        "                              \": 1\",{'cloudmsk': img1.select('cloudmsk')}).rename('c').clip(poly)\n",
        "      return(classes)\n",
        "\n",
        "  if dattype.startswith('S2'):\n",
        "      post_mosaic_cc = post_mosaic_col.map(classify_cc).toBands()\n",
        "      aot = post_mosaic_col.select('AOT').toBands().divide(1000)\n",
        "      reduced_mean_aot = aot.reduceRegion(reducer=ee.Reducer.mean(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "  else:\n",
        "      post_mosaic_cloudmsk = post_mosaic_col.map(get_cloud)\n",
        "      post_mosaic_cc = post_mosaic_cloudmsk.map(classify_cc).toBands()\n",
        "\n",
        "  #Calculate statistics, if the image is too big this may fail.\n",
        "  #This step causes problems sometimes due to maxPixels limits\n",
        "  reduced_sum = post_mosaic_extent.reduceRegion(reducer=ee.Reducer.sum(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "  reduced_count = post_mosaic_extent.reduceRegion(reducer=ee.Reducer.count(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "\n",
        "  reduced_sum_cc = post_mosaic_cc.reduceRegion(reducer=ee.Reducer.sum(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "  reduced_count_cc = post_mosaic_cc.reduceRegion(reducer=ee.Reducer.count(),geometry=poly.geometry(),maxPixels=100000000000,scale=30).getInfo()\n",
        "\n",
        "  print('Image statistics calculated')\n",
        "\n",
        "  #Rearrange and calculate percent coverage and percent cloud cover\n",
        "  #extent\n",
        "  df_sum = pd.DataFrame([reduced_sum]).T\n",
        "  df_sum.columns = ['sum']\n",
        "\n",
        "  df_count = pd.DataFrame([reduced_count]).T\n",
        "  df_count.columns = ['count']\n",
        "\n",
        "  df_perc = df_sum.join(df_count)\n",
        "  df_perc['percent_coverage'] = (df_perc['sum']/df_perc['count'])*100\n",
        "\n",
        "  #cloud cover\n",
        "  df_sum_cc = pd.DataFrame([reduced_sum_cc]).T\n",
        "  df_sum_cc.columns = ['sum_cc']\n",
        "\n",
        "  df_count_cc = pd.DataFrame([reduced_count_cc]).T\n",
        "  df_count_cc.columns = ['count_cc']\n",
        "\n",
        "  df_perc_cc = df_sum_cc.join(df_count_cc)\n",
        "  df_perc_cc['percent_cc'] = (df_perc_cc['sum_cc']/df_perc_cc['count_cc'])*100\n",
        "  #print(df_perc_cc)\n",
        "\n",
        "  if dattype.startswith('S'):\n",
        "      #aot\n",
        "      df_mean_aot = pd.DataFrame([reduced_mean_aot]).T\n",
        "      df_mean_aot.columns = ['mean_aot']\n",
        "\n",
        "      #join extent and cc\n",
        "      meta_df_ext_temp = df_perc.join(df_perc_cc)\n",
        "\n",
        "      #get rid of cc suffix\n",
        "      oldnames = meta_df_ext_temp.index\n",
        "      newnames = [s.rsplit('_')[0] for s in oldnames]\n",
        "      meta_df_ext_temp.index = newnames\n",
        "\n",
        "      #get rid of aot suffix\n",
        "      oldnames = df_mean_aot.index\n",
        "      newnames = [s.rsplit('_')[0] for s in oldnames]\n",
        "      df_mean_aot.index = newnames\n",
        "\n",
        "      meta_df_ext = meta_df_ext_temp.join(df_mean_aot)\n",
        "      #print(meta_df_ext)\n",
        "\n",
        "  else:\n",
        "      #join extent and cc\n",
        "      meta_df_ext = df_perc.join(df_perc_cc)\n",
        "\n",
        "      #get rid of cc suffix\n",
        "      oldnames = meta_df_ext.index\n",
        "      newnames = [s.rsplit('_')[0] for s in oldnames]\n",
        "      meta_df_ext.index = newnames\n",
        "\n",
        "  #get average scene cloud cover and join to mosaic metadata\n",
        "  post_meta_scenes_cld = post_meta_scenes.groupby('date')[cld_field].mean()\n",
        "  temp = pd.DataFrame(post_meta_scenes_cld)\n",
        "  post_meta_scenes_cld = temp.rename(columns={'date':'date',cld_field:'percent_cc_scene'})\n",
        "\n",
        "  meta_df_ext = meta_df_ext.join(post_meta_scenes_cld)\n",
        "  meta_df_ext_out = meta_df_ext.copy().round(2).drop(columns=['sum','count','sum_cc','count_cc'])\n",
        "  meta_df_ext_out['sensor'] = dattype\n",
        "\n",
        "  if 'mean_aot' not in meta_df_ext_out.columns:\n",
        "    meta_df_ext_out['mean_aot'] = None\n",
        "\n",
        "  outpath = os.path.join(outfolder,firenumber+'_'+dattype+'_post_mosaicMetadata.csv')\n",
        "  meta_df_ext_out.to_csv(outpath)\n",
        "  df_list.append(meta_df_ext_out)\n",
        "  print('Dataframe prepared')\n",
        "\n",
        "#Output final post-fire dataframe and save\n",
        "post_df = pd.concat(df_list)\n",
        "outpath2 = os.path.join(outfolder,firenumber+'_all_post_mosaicMetadata.csv')\n",
        "post_df.to_csv(outpath2)"
      ],
      "metadata": {
        "id": "s4MG2lCNfgv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize post-fire image availability\n",
        "post_df"
      ],
      "metadata": {
        "id": "bHuntDCDi4kr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}