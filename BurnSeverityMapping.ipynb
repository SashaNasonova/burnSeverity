{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SashaNasonova/burnSeverity/blob/main/BurnSeverityMapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0djxgBzOnOM8"
      },
      "source": [
        "# Burn Severity Mapping Notebook\n",
        "This notebook is intended to be used for small scale, interactive burn severity mapping of individual fires. For large scale semi-automated mapping please refer to the main python scripts (https://github.com/SashaNasonova/burnSeverity).\n",
        "\n",
        "The methodology is based on the Burned Area Reflectance Classification (BARC) product developed by the USGS that aims to estimate burn severity through a spectral comparison of pre- and post-fire medium resolution (20 - 30m) satellite imagery.\n",
        "\n",
        "Healthy vegetation reflects strongly in the near-infrared (NIR) portion of the electromagnetic spectrum whereas rock and bare soil reflects strongly in the mid to shortwave infrared (SWIR) portion. In other words, healthy vegetation reflects strongly in NIR and reflects weakly in SWIR **(↑NIR,↓SWIR)**, whereas soil, bare rock and burned woody vegetation reflect strongly in SWIR and weakly in NIR **(↑SWIR,↓NIR)**. This inverse relationship can be leveraged to provide an estimate of burn severity where both pre- and post-fire imagery is available.\n",
        "\n",
        "The Normalized Burn Ratio (NBR) is a spectral index that captures the relationship between NIR and SWIR bands. The difference between pre- and post-fire NBR (dNBR) can then be used to quantify wildfire burn severity (**↑dNBR ∝ ↑Severity**) using the following equations.\n",
        "\n",
        "(1) NBR = (NIR - SWIR) / (NIR + SWIR) \\\\\n",
        "(2) dNBR = NBRpre - NBRpost\n",
        "\n",
        "Once dNBR has been calculated, it can be transformed into a burn severity classification product using a variety of methods ranging from simple thresholding to more complex supervised classifications informed by ground observations. This process is based on the USGS BARC256 methodology which scales the data to an 8-bit representation and utilizes static thresholds (76,110,187) to create a burn severity classification from the dNBR raster.\n",
        "\n",
        "This notebook is broken up into the following sections:\n",
        "\n",
        "1. Set up (data import, package installation, library loading)\n",
        "2. Google Earth Engine authentication and initialization\n",
        "3. Fire perimeter import and visualization\n",
        "4. Individual fire perimeter selection (1 fire perimeter)\n",
        "5. Sensor selection\n",
        "6. Pre-fire image search, visualization and selection\n",
        "7. Post-fire image search, visualization and selection\n",
        "8. BARC mapping\n",
        "9. Final visualization for quality control\n",
        "10. Image download\n",
        "11. Quicklooks and area burned by severity class\n",
        "12. Final export\n",
        "\n",
        "Before beginning, please ensure that you are registered to use Google Earth Engine and have the Google Earth Engine API enabled as part of a Google Cloud project. If that is not the case, please follow the instructions on getting started (https://github.com/SashaNasonova/burnSeverity/blob/main/Getting_Started_with_GEE.md). You will need to take note of the project id and enter it later on."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KzjQ6j4CfOGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1: Set-up**"
      ],
      "metadata": {
        "id": "jGYix91SfTew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone github repository to be able to access the test data and provincial extent vector data\n",
        "!git clone https://github.com/SashaNasonova/burnSeverity.git"
      ],
      "metadata": {
        "id": "sxuYFlcIfDwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH_EYpac23-Y"
      },
      "outputs": [],
      "source": [
        "# Install the libraries\n",
        "%pip install -U geemap\n",
        "%pip install pycrs rasterio python-pptx cartopy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "import ee\n",
        "import geemap\n",
        "import os, json\n",
        "import geopandas\n",
        "from osgeo import gdal\n",
        "from google.colab import files\n",
        "\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "from pptx import Presentation\n",
        "from pptx.util import Cm, Inches\n",
        "from pptx.util import Pt"
      ],
      "metadata": {
        "id": "YDrM7Sswf9pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define functions"
      ],
      "metadata": {
        "id": "LTi0frCUCpkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhhl6ZZSLfQ4"
      },
      "outputs": [],
      "source": [
        "## Define functions\n",
        "# Helper function to get files, non-recursive\n",
        "def getfiles(d,ext):\n",
        "  paths = []\n",
        "  for file in os.listdir(d):\n",
        "      if file.endswith(ext):\n",
        "          paths.append(os.path.join(d, file))\n",
        "  return(paths)\n",
        "\n",
        "# Helper function to get image acquisition date and format into (\"yyyy-mm-dd\")\n",
        "def getDate(im):\n",
        "  return(ee.Image(im).date().format(\"YYYY-MM-dd\"))\n",
        "\n",
        "# Helper function to get scene ids\n",
        "def getSceneIds(im):\n",
        "  return(ee.Image(im).get('PRODUCT_ID'))\n",
        "\n",
        "# Functions to mosaic by image date\n",
        "def mosaicByDate(indate):\n",
        "  d = ee.Date(indate)\n",
        "  #print(d)\n",
        "  im = col.filterBounds(poly).filterDate(d, d.advance(1, \"day\")).mosaic()\n",
        "  #print(im)\n",
        "  return(im.set(\"system:time_start\", d.millis(), \"system:index\", d.format(\"YYYY-MM-dd\")))\n",
        "\n",
        "def runDateMosaic(col_list):\n",
        "  #get a list of unique dates within the list\n",
        "  date_list = col_list.map(getDate).getInfo()\n",
        "  udates = list(set(date_list))\n",
        "  udates.sort()\n",
        "  udates_ee = ee.List(udates)\n",
        "\n",
        "  #mosaic images by unique date\n",
        "  mosaic_imlist = udates_ee.map(mosaicByDate)\n",
        "  return(ee.ImageCollection(mosaic_imlist))\n",
        "\n",
        "# Calculate NBR using Sentinel-2 imagery\n",
        "def NBR_S2(image):\n",
        "  nbr = image.expression(\n",
        "      '(NIR - SWIR) / (NIR + SWIR)', {\n",
        "          'NIR': image.select('B8'),\n",
        "          'SWIR': image.select('B12')}).rename('nbr')\n",
        "  return(nbr)\n",
        "\n",
        "# Calculate NBR using Landsat imagery\n",
        "# Handles Landsat-5, 7, 8 and 9\n",
        "def NBR_Landsat(image,dattype):\n",
        "  if (dattype == 'L5')|(dattype == 'L7'):\n",
        "      nbr = image.expression(\n",
        "          '(NIR - SWIR) / (NIR + SWIR)', {\n",
        "              'NIR': image.select('SR_B4'),\n",
        "              'SWIR': image.select('SR_B7')}).rename('nbr')\n",
        "  elif (dattype == 'L8')|(dattype == 'L9'):\n",
        "      nbr = image.expression(\n",
        "          '(NIR - SWIR) / (NIR + SWIR)', {\n",
        "              'NIR': image.select('SR_B5'),\n",
        "              'SWIR': image.select('SR_B7')}).rename('nbr')\n",
        "  else:\n",
        "      print('Incorrect Landsat sensor specified')\n",
        "  return(nbr)\n",
        "\n",
        "# Tiling function, uses a geometry (footprint) to split into a defined\n",
        "# number or rows and columns (nx,ny)\n",
        "def grid_footprint(footprint,nx,ny):\n",
        "  from shapely.geometry import Polygon, LineString, MultiPolygon\n",
        "  from shapely.ops import split\n",
        "\n",
        "  #polygon = footprint\n",
        "  polygon = Polygon(footprint['coordinates'][0])\n",
        "  #polygon = Polygon(footprint)\n",
        "\n",
        "  minx, miny, maxx, maxy = polygon.bounds\n",
        "  dx = (maxx - minx) / nx  # width of a small part\n",
        "  dy = (maxy - miny) / ny  # height of a small part\n",
        "\n",
        "  horizontal_splitters = [LineString([(minx, miny + i*dy), (maxx, miny + i*dy)]) for i in range(ny)]\n",
        "  vertical_splitters = [LineString([(minx + i*dx, miny), (minx + i*dx, maxy)]) for i in range(nx)]\n",
        "  splitters = horizontal_splitters + vertical_splitters\n",
        "\n",
        "  result = polygon\n",
        "  for splitter in splitters:\n",
        "      result = MultiPolygon(split(result, splitter))\n",
        "\n",
        "  coord_list = [list(part.exterior.coords) for part in result.geoms]\n",
        "\n",
        "  poly_list = []\n",
        "  for cc in coord_list:\n",
        "      p = ee.Geometry.Polygon(cc)\n",
        "      poly_list.append(p)\n",
        "  return(poly_list)\n",
        "\n",
        "# Applies scaling functors for surface reflectance Landsat imagery\n",
        "def apply_scale_factors_ls(image):\n",
        "  opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
        "  thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
        "  return image.addBands(opticalBands, None, True).addBands(thermalBands, None, True)\n",
        "\n",
        "# Multiplies Sentinel-2 imagery by 0.0001\n",
        "def apply_scale_factors_s2(image):\n",
        "  opticalBands = image.select('B.*').multiply(0.0001)\n",
        "  return image.addBands(opticalBands, None, True)\n",
        "\n",
        "### QA Functions ###\n",
        "def ql_3band(outshp,imgpath,outpath):\n",
        "  # Get fire vector\n",
        "  dfs_sub = geopandas.read_file(outshp)\n",
        "\n",
        "  # Read 8-bit image\n",
        "  src = rasterio.open(imgpath)\n",
        "\n",
        "  # Create pre-fire quicklook image with burned area boundary overlay\n",
        "  fig, ax = plt.subplots(figsize=(8, 8)) #10,13\n",
        "  base = show(src,ax=ax)\n",
        "  dfs_sub.plot(ax=base, edgecolor='purple', facecolor='none',linewidth=2)\n",
        "  ax.axis('off')\n",
        "  plt.savefig(outpath, bbox_inches='tight', dpi=300)\n",
        "\n",
        "  plt.close()\n",
        "  src = None\n",
        "\n",
        "def generate_legend_labels(arr):\n",
        "  #sort array\n",
        "  arr.sort()\n",
        "\n",
        "  default_labels = {\n",
        "      0: {\"black\":\"Unknown\"},\n",
        "      1: {\"gray\":\"Unburned\"},\n",
        "      2: {\"yellow\":\"Low\"},\n",
        "      3: {\"orange\":\"Medium\"},\n",
        "      4: {\"red\":\"High\"}\n",
        "  }\n",
        "\n",
        "  legend_labels = {}\n",
        "\n",
        "  for value in arr:\n",
        "      #print(default_labels[value]) #for debug\n",
        "      legend_labels.update(default_labels[value])\n",
        "\n",
        "  return(legend_labels)\n",
        "\n",
        "\n",
        "def ql_barc(outshp,barcpath,imgpath,outpath):\n",
        "  dfs_sub = geopandas.read_file(outshp)\n",
        "\n",
        "  # Read in BARC classification\n",
        "  src = rasterio.open(barcpath)\n",
        "  unique_values = np.unique(src.read(1))\n",
        "\n",
        "  # Read in post-fire image\n",
        "  src1 = rasterio.open(imgpath)\n",
        "\n",
        "  #drop no data 9\n",
        "  arr = unique_values[unique_values!=9]\n",
        "\n",
        "  # Create cmap dictionary\n",
        "  colormap_dict = {0: 'black',\n",
        "                    1: 'gray',\n",
        "                    2: 'yellow',\n",
        "                    3: 'orange',\n",
        "                    4: 'red'}\n",
        "\n",
        "  colormap_unique = [colormap_dict[value] for value in arr]\n",
        "  colormap = matplotlib.colors.ListedColormap(colormap_unique)\n",
        "\n",
        "  # Create pre-fire quicklook image with burned area boundary overlay\n",
        "  fig, ax = plt.subplots(figsize=(8, 8))\n",
        "  background = show((src1,1),ax=ax,cmap='gray')\n",
        "  base = show(src,cmap=colormap,ax=ax)\n",
        "  dfs_sub.plot(ax=base, edgecolor='purple', facecolor='none',linewidth=2)\n",
        "  ax.axis('off')\n",
        "\n",
        "  legend_labels = generate_legend_labels(arr)\n",
        "\n",
        "  patches = [Patch(color=color, label=label)\n",
        "              for color, label in legend_labels.items()]\n",
        "\n",
        "  ax.legend(handles=patches,\n",
        "            bbox_to_anchor=(1.05, 1),loc='upper left',\n",
        "            borderaxespad=0., facecolor=\"white\")\n",
        "\n",
        "\n",
        "  plt.savefig(outpath, bbox_inches='tight', dpi=300)\n",
        "\n",
        "  plt.close()\n",
        "  src = None\n",
        "  src1 = None\n",
        "\n",
        "# Generate quicklooks\n",
        "def generate_ql(outshp,tif_file,qcdir):\n",
        "  name = Path(tif_file).stem + '.png'\n",
        "  ql = os.path.join(qcdir,name)\n",
        "  ql_3band(outshp,tif_file,ql)\n",
        "  return(ql)\n",
        "\n",
        "def create_ppt(pptpath):\n",
        "  prs = Presentation()\n",
        "  prs.slide_width = Inches(16)\n",
        "  prs.slide_height = Inches(9)\n",
        "\n",
        "  prs.save(pptpath)\n",
        "\n",
        "def add_slide(pptpath,i,j,k,l,df):\n",
        "  prs = Presentation(pptpath)\n",
        "  title_only_slide_layout = prs.slide_layouts[5]\n",
        "  slide = prs.slides.add_slide(title_only_slide_layout)\n",
        "  title = slide.shapes.title\n",
        "  title.width = Cm(35)\n",
        "  title.height = Cm(3.3)\n",
        "  title.top = Cm(0)\n",
        "  title.left = Cm(0)\n",
        "\n",
        "  #Add title\n",
        "  name = Path(k).stem\n",
        "  title.text = name\n",
        "\n",
        "  #First image (pre-fire)\n",
        "  slide.shapes.add_picture(\n",
        "      i, left=Cm(0.44), top=Cm(8.2), width=Cm(12.24), height=None\n",
        "  )\n",
        "  #Second image (post_fire)\n",
        "  slide.shapes.add_picture(\n",
        "      j, left=Cm(12.78), top=Cm(8.2), width=Cm(12.24), height=None\n",
        "  )\n",
        "\n",
        "  #get image height\n",
        "  picture = slide.shapes[1] #second shape pre-img, first is the title\n",
        "  height_cm = picture.height.cm\n",
        "  #print(height_cm)\n",
        "\n",
        "  #Third image (barc)\n",
        "  slide.shapes.add_picture(\n",
        "      k, left=Cm(25.02), top=Cm(8.2), width=None, height=Cm(height_cm)\n",
        "  )\n",
        "\n",
        "  #Fourth image (location map)\n",
        "  slide.shapes.add_picture(\n",
        "      l, left=Cm(32.5), top=Cm(0), width=None, height=Cm(7)\n",
        "  )\n",
        "\n",
        "  #add table\n",
        "  rows, cols = df.shape\n",
        "  left = Cm(0.9)\n",
        "  top = Cm(3.2)\n",
        "  width = Cm(16.3)\n",
        "  height = Cm(3.75)\n",
        "\n",
        "  #add table\n",
        "  shape = slide.shapes.add_table(rows + 1, cols, left, top, width, height)\n",
        "  table = shape.table\n",
        "\n",
        "  #assign table style\n",
        "  tbl =  shape._element.graphic.graphicData.tbl\n",
        "  style_id = '{C083E6E3-FA7D-4D7B-A595-EF9225AFEA82}'\n",
        "  tbl[0][-1].text = style_id\n",
        "\n",
        "\n",
        "  # Set column names\n",
        "  for col, column_name in enumerate(df.columns):\n",
        "      cell = table.cell(0, col)\n",
        "      cell.text = column_name\n",
        "      cell.text_frame.paragraphs[0].runs[0].font.size = Pt(11)\n",
        "\n",
        "  # Populate data\n",
        "  for row in range(rows):\n",
        "      for col in range(cols):\n",
        "          cell = table.cell(row + 1, col)\n",
        "          cell.text = str(df.iloc[row, col])\n",
        "\n",
        "  # Change font size\n",
        "  for row in table.rows:\n",
        "      for cell in row.cells:\n",
        "          for paragraph in cell.text_frame.paragraphs:\n",
        "              for run in paragraph.runs:\n",
        "                  run.font.size = Pt(11)\n",
        "\n",
        "  prs.save(pptpath) #this overwrites\n",
        "  print('Presentation saved')\n",
        "\n",
        "def ql_3band_batch(folder,outshp,outfolder):\n",
        "  imglist = getfiles(folder,'.tif')\n",
        "  for imgpath in imglist:\n",
        "      name = Path(imgpath).stem + '.png'\n",
        "      outpath = os.path.join(outfolder,name)\n",
        "      ql_3band(outshp,imgpath,outpath)\n",
        "\n",
        "def add_slides_batch(img_folder,pptpath):\n",
        "  imglist = getfiles(img_folder,'.png')\n",
        "\n",
        "  prs = Presentation(pptpath)\n",
        "  title_only_slide_layout = prs.slide_layouts[5]\n",
        "\n",
        "  for i in imglist:\n",
        "      print(i)\n",
        "      slide = prs.slides.add_slide(title_only_slide_layout)\n",
        "      title = slide.shapes.title\n",
        "      title.width = Cm(35)\n",
        "      title.height = Cm(3.3)\n",
        "      title.top = Cm(0)\n",
        "      title.left = Cm(0)\n",
        "\n",
        "      #Add title\n",
        "      name = Path(i).stem\n",
        "      title.text = name\n",
        "\n",
        "      slide.shapes.add_picture(\n",
        "          i, left=Cm(12.78), top=Cm(3.7), width=Cm(12.24), height=None\n",
        "      )\n",
        "  prs.save(pptpath)\n",
        "\n",
        "def inset_map(bc_path,fire_perim,outpath):\n",
        "  # Define the bounding box for British Columbia (lonmin, lonmax, latmin, latmax)\n",
        "  bbox = [-139, -114.75, 47.5, 60]\n",
        "\n",
        "\n",
        "  # Coordinates of cities/towns (latitude, longitude)\n",
        "  cities = {\n",
        "      'Vancouver': (49.2827, -123.1207),\n",
        "      'Kamloops': (50.6761, -120.3408),\n",
        "      'Prince George':(53.9170,-122.7494),\n",
        "      'Fort St John': (56.2464,-120.8476),\n",
        "      'Prince Rupert': (54.3125,-130.3054),\n",
        "      'Williams Lake': (52.1284,-122.1302)\n",
        "\n",
        "  }\n",
        "\n",
        "  # Create a map\n",
        "  plt.figure(figsize=(4,4))\n",
        "  ax = plt.axes(projection=ccrs.AlbersEqualArea(central_longitude=-126, central_latitude=54))\n",
        "  ax.set_extent(bbox, crs=ccrs.PlateCarree())\n",
        "\n",
        "  # Add land and coastline features\n",
        "  ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgrey',linewidth=0.1)\n",
        "  ax.add_feature(cfeature.COASTLINE, linewidth=0.1)\n",
        "\n",
        "  # Load the British Columbia boundary data using GeoPandas\n",
        "  ## Thank you GeoBC! https://catalogue.data.gov.bc.ca/dataset/province-of-british-columbia-boundary-terrestrial\n",
        "  bc_boundary = geopandas.read_file(bc_path)\n",
        "\n",
        "  # Plot the British Columbia boundary using Cartopy's geopandas tools\n",
        "  ax.add_geometries(bc_boundary['geometry'], crs=ccrs.PlateCarree(), edgecolor='black', facecolor='green',linewidth=0.1)\n",
        "\n",
        "  # Add gridlines\n",
        "  ax.gridlines(draw_labels=True, linestyle='--', color='grey')\n",
        "\n",
        "  # Add fire boundary\n",
        "  fire_boundary = geopandas.read_file(fire_perim)\n",
        "  fire_boundary[\"centroid\"] = fire_boundary[\"geometry\"].centroid\n",
        "  lat = fire_boundary[\"centroid\"].y\n",
        "  lon = fire_boundary[\"centroid\"].x\n",
        "  ax.plot(lon,lat, marker='*', color='purple', markersize=5, transform=ccrs.PlateCarree())\n",
        "  ax.text(lon + 0.5, lat, 'Fire Location', color='purple', fontsize=8, transform=ccrs.PlateCarree())\n",
        "\n",
        "  # Add cities/towns\n",
        "  for city, (lat, lon) in cities.items():\n",
        "      ax.plot(lon, lat, marker='o', color='black', markersize=3, transform=ccrs.PlateCarree())\n",
        "      ax.text(lon + 0.5, lat, city, color='black', fontsize=7, transform=ccrs.PlateCarree())\n",
        "\n",
        "  plt.savefig(outpath, bbox_inches='tight', dpi=300)\n",
        "  plt.close()\n",
        "\n",
        "# Calculates burn area by severity class\n",
        "def zonal_barc(barcpath,firepath,outpath):\n",
        "  def burnsev_name(x):\n",
        "      if x == 0:\n",
        "          return('Unknown')\n",
        "      elif x == 1:\n",
        "          return('Unburned')\n",
        "      elif x == 2:\n",
        "          return('Low')\n",
        "      elif x == 3:\n",
        "          return('Medium')\n",
        "      elif x == 4:\n",
        "          return('High')\n",
        "      else:\n",
        "          print(\"Wrong burn severity value!\")\n",
        "\n",
        "\n",
        "  #need to clip to fire perimeter a little tighter than what gee outputs\n",
        "  basename = barcpath[:-4]\n",
        "  barcpath_clip = basename + '_clip.tif'\n",
        "\n",
        "  gdal.Warp(barcpath_clip,barcpath,cutlineDSName=firepath,cropToCutline=True)\n",
        "\n",
        "  dat = gdal.Open(barcpath_clip)\n",
        "  band = dat.GetRasterBand(1).ReadAsArray()\n",
        "\n",
        "  x1,px,x2,x3,x4,x5 = dat.GetGeoTransform()\n",
        "\n",
        "  nodatavalue = 9\n",
        "  vals, counts = np.unique(band[band != nodatavalue], return_counts=True)\n",
        "\n",
        "  df = pd.DataFrame(\n",
        "      {'class':vals,\n",
        "        'px_count':counts})\n",
        "\n",
        "\n",
        "  a = df['px_count'].sum()\n",
        "  df['perc' ] = (df['px_count'] / a)*100\n",
        "  df['area_m2'] = df['px_count']*(px*px)\n",
        "  df['area_ha'] = df['area_m2']*0.0001\n",
        "\n",
        "  #round to 1 decimal place\n",
        "  df = df.round(1)\n",
        "  df['burn_sev'] = df['class'].apply(burnsev_name)\n",
        "\n",
        "  #reorder columns\n",
        "  df = df[['class','burn_sev','px_count','area_m2','area_ha','perc']]\n",
        "\n",
        "  #print(df) #debug\n",
        "  df.to_csv(outpath)\n",
        "  return(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LNg4P_7yfvVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2: Google Earth Engine authentication and initialization**"
      ],
      "metadata": {
        "id": "Vm7FVLD5fnTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate and intialize GEE. After running the cell below, a sign-in window will pop-up. Please follow prompts to authenticate (sign-in, continue and continue)."
      ],
      "metadata": {
        "id": "FefjxDuKl_VW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlgKaTt1GJXt"
      },
      "outputs": [],
      "source": [
        "#Authenticate gee\n",
        "ee.Authenticate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Please note, the **Project ID** may be something other than the project name (ex. burn-severity-2024) and may contain additional numbers (ex. burn-severity-2024-456181). Make sure to copy the actual **Project ID** and enter it in the cell below."
      ],
      "metadata": {
        "id": "fmegNSt5c1BO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni-CYcoVGNYF"
      },
      "outputs": [],
      "source": [
        "# Intialize with a google cloud project\n",
        "project = 'burn-severity-2024'\n",
        "ee.Initialize(project=project)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gdIaeamnhKFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 3: Fire perimeter import and visualization**"
      ],
      "metadata": {
        "id": "iG4frcaXg-1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below will load in a polygon shapefile and display the attribute table. The fire_shp variable is the path to your dataset."
      ],
      "metadata": {
        "id": "OXAzWYeKvp5s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "At6EOWMfMIGL"
      },
      "outputs": [],
      "source": [
        "# Open fires shapefile\n",
        "fires_shp = 'burnSeverity/test/vectors/K52318_Aug28.shp'\n",
        "fires = geemap.shp_to_ee(fires_shp)\n",
        "\n",
        "# Visualize in table format\n",
        "fires_df = geopandas.read_file(fires_shp)\n",
        "fires_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now visualize spatially."
      ],
      "metadata": {
        "id": "eTWM3d97jQFj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUwlkFb1M2yS"
      },
      "outputs": [],
      "source": [
        "Map = geemap.Map()\n",
        "Map.addLayer(fires,{},'Fire Polys')\n",
        "Map.centerObject(fires)\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xuxdEJDiiO3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 4: Individual fire perimeter selection (1 fire perimeter)**"
      ],
      "metadata": {
        "id": "95ZXcVZ7iQg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select one fire perimeter by fire number. Please make sure that the **fieldname** variable matches your dataset."
      ],
      "metadata": {
        "id": "NMRQT7CiwOt8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP9ywAhpkCOC"
      },
      "outputs": [],
      "source": [
        "# Now select one fire (in the test data, there's only one fire perimeter)\n",
        "firenumber = 'K52318' #change fire name\n",
        "fieldname = 'FIRE_NUMBE' #unique firenumber field, change if needed\n",
        "\n",
        "# Create output folder\n",
        "if not os.path.exists(firenumber):\n",
        "  os.mkdir(firenumber)\n",
        "\n",
        "# Save a copy of the fire perimeter\n",
        "vector_folder = os.path.join(firenumber,'vectors')\n",
        "if not os.path.exists(vector_folder):\n",
        "  os.mkdir(vector_folder)\n",
        "\n",
        "outshp = os.path.join(vector_folder,firenumber+'.shp')\n",
        "fires_df_sub = fires_df[fires_df['FIRE_NUMBE']==firenumber]\n",
        "fires_df_sub.to_file(outshp,driver='ESRI Shapefile')\n",
        "\n",
        "# Load in the single perimeter\n",
        "poly = geemap.shp_to_ee(outshp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_kggzNsKiuDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 5: Sensor selection**"
      ],
      "metadata": {
        "id": "LkgJM6Tjiyun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The sensor options are as follows: Sentinel-2a/b MSI (S2), Landsat-8 OLI (L8) or Landsat-9 OLI-2 (L9). The data from the above sensors are the surface reflectance / bottom of atmosphere processing level. Please note, pre- and post-fire imagery wil be selected from the same sensor. We have not investigated combining Landsat-8 OLI and Landsat-9 OLI-2 data yet. Imagery from the two Landsat sensors should be fairly comparable with an expected difference of approximately 2% for forests (https://www.tandfonline.com/doi/full/10.1080/15481603.2024.2318071). However, in the above study bare land shows higher deviations (>2.5%) which may be problematic for this application. These differences can potentially be mitigated by the harmonzed landsat product (HLSL30: https://developers.google.com/earth-engine/datasets/catalog/NASA_HLS_HLSL30_v002) but should be investigated further."
      ],
      "metadata": {
        "id": "kPSFM4RovjRU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0NN6etOk8jx"
      },
      "outputs": [],
      "source": [
        "dattype = 'S2' #change sensor here\n",
        "\n",
        "if dattype == 'S2':\n",
        "    col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "    cld_field =  'CLOUDY_PIXEL_PERCENTAGE'\n",
        "    print('Selected S2 SR')\n",
        "elif dattype == 'L9':\n",
        "    col = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n",
        "    cld_field = 'CLOUD_COVER'\n",
        "    print('Selected L9 SR')\n",
        "elif dattype == 'L8':\n",
        "    col = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
        "    cld_field = 'CLOUD_COVER'\n",
        "    print('Selected L8 SR')\n",
        "else:\n",
        "    print('Wrong Data Type Selected')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization parameters**: choose the type of visualization you would like to use. Default is false-colour infrared ('nir') but true-color ('tc') and shortwave-infrared ('swir') are also available."
      ],
      "metadata": {
        "id": "Sen9AWOCwUvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define visualization parameters\n",
        "vis_type = 'nir'\n",
        "\n",
        "# Dictionary with band combinations\n",
        "vis_dict = {'L8':{'nir':['SR_B5', 'SR_B4', 'SR_B3'],\n",
        "                  'tc':['SR_B4','SR_B3','SR_B2'],\n",
        "                  'swir':['SR_B7','SR_B6','SR_B4']},\n",
        "            'L9':{'nir':['SR_B5', 'SR_B4', 'SR_B3'],\n",
        "                  'tc':['SR_B4','SR_B3','SR_B2'],\n",
        "                  'swir':['SR_B7','SR_B6','SR_B4']},\n",
        "            'S2':{'nir':['B8', 'B4', 'B3'],\n",
        "                  'tc':['B4','B3','B2'],\n",
        "                  'swir':['B12','B8','B4']}}\n",
        "\n",
        "bands = vis_dict[dattype][vis_type] #or provide a list of 3 bands\n",
        "\n",
        "vis = {\n",
        "  'min': 0,\n",
        "  'max': 0.4,\n",
        "  'bands': bands,\n",
        "};"
      ],
      "metadata": {
        "id": "F5AxJwrOO-8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "grIi4UVHwCDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 6: Pre-fire image search, visualization and selection**"
      ],
      "metadata": {
        "id": "LbD3pGmOwSpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the time-interval for the pre-fire image search (startdate_pre and enddate_pre). The imagery should be selected either from year of the fire or the year before. The optimal window for image selection is July 1st to September 30. If good quality imagery isn't available, then search previous year's imagery. To avoid phenology differences, it is best to select pre- and post-fire imagery that is as seasonally consistent as possible. For example both and pre- and post-fire imagery acquired in early August.\n",
        "\n",
        "The script below will search the archive for images acquired during the defined time interval (not inclusive of the enddate), overlapping with the fire perimeter, and below the defined cloud cover threshold. The resulting images are then mosaicked by image acquisition day (along track). If you are searching a wide range time range, it is best to reduce the cloud threshold (cld_thr_pre) to 40 or less.\n"
      ],
      "metadata": {
        "id": "58PGY6NUOtI7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA3mf-74kHtb"
      },
      "outputs": [],
      "source": [
        "# Find pre-fire imagery\n",
        "startdate_pre = '2023-07-15'\n",
        "enddate_pre = '2023-07-30'\n",
        "cld_thr_pre = 100 #this is the cloud cover threshold from the scene metadata\n",
        "\n",
        "before = col.filterDate(startdate_pre,enddate_pre).filterBounds(poly).filter(ee.Filter.lt(cld_field,cld_thr_pre))\n",
        "\n",
        "before_list = before.toList(before.size().getInfo())\n",
        "pre_mosaic_col = runDateMosaic(before_list)\n",
        "\n",
        "if dattype.startswith('L'):\n",
        "  pre_mosaic_col = pre_mosaic_col.map(apply_scale_factors_ls)\n",
        "else:\n",
        "  pre_mosaic_col = pre_mosaic_col.map(apply_scale_factors_s2)\n",
        "\n",
        "print('Found',pre_mosaic_col.size().getInfo(),'dates')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-fire image map display:** display the imagery found."
      ],
      "metadata": {
        "id": "SPGX_tSfO9Uv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tJAK85Qrmym"
      },
      "outputs": [],
      "source": [
        "# Add pre-fire images to pre-fire map\n",
        "before_map = geemap.Map()\n",
        "\n",
        "before_size = pre_mosaic_col.size().getInfo()\n",
        "before_mosaic_list = pre_mosaic_col.toList(before_size)\n",
        "before_size\n",
        "\n",
        "for i in range(0,before_size):\n",
        "  b = before_mosaic_list.get(i)\n",
        "  date = b.getInfo()['properties']['system:index']\n",
        "  before_map.addLayer(ee.Image(b), vis, date)\n",
        "  print(date)\n",
        "\n",
        "# Add fire polygon\n",
        "style = {'color': 'white', 'width': 2, 'lineType': 'solid', 'fillColor': '00000000'}\n",
        "before_map.addLayer(poly.style(**style),{},'poly')\n",
        "before_map.centerObject(poly)\n",
        "before_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw89bta2L0t-"
      },
      "source": [
        "In the top right corner of the map, select the option to list all the layers and toggle on and off the dates to inspect the imagery. Find a high quality image, free of cloud, smoke, as well as snow and take note of the date(yyyy-mm-dd). You can copy and paste the date from the output of the cell above. If there's no clear imagery available for the date you range you defined you can try a different date range or go back and select a different sensor (dattype)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qs-CxbOX4NV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 7: Post-fire image search, visualization and selection**"
      ],
      "metadata": {
        "id": "qJ_8S_OY4QBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now select the time-interval for the post-fire image search (startdate_post and enddate_post). As with the pre-fire imagery, the optimal window for image selection is July 1st to September 30. However, that will not be possible, especially for the fires later in the season. If possible, try to select imagery from before October 15th."
      ],
      "metadata": {
        "id": "m4HCFMWpPC4F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aypsWNvCpQ6I"
      },
      "outputs": [],
      "source": [
        "# Find post-fire images\n",
        "startdate_post = '2023-09-15'\n",
        "enddate_post = '2023-09-30' #not inclusive of the end date\n",
        "cld_thr_post = 100\n",
        "\n",
        "after = col.filterDate(startdate_post,enddate_post).filterBounds(poly).filter(ee.Filter.lt(cld_field,cld_thr_post))\n",
        "\n",
        "after_list = after.toList(after.size().getInfo())\n",
        "post_mosaic_col = runDateMosaic(after_list)\n",
        "\n",
        "if dattype.startswith('L'):\n",
        "  post_mosaic_col = post_mosaic_col.map(apply_scale_factors_ls)\n",
        "else:\n",
        "  post_mosaic_col = post_mosaic_col.map(apply_scale_factors_s2)\n",
        "\n",
        "print('Found',post_mosaic_col.size().getInfo(),'scenes')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Post-fire image map display**: display the post-fire imagery in a new map."
      ],
      "metadata": {
        "id": "Txm_d2SxwiA1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrEp5JtAUDMN"
      },
      "outputs": [],
      "source": [
        "# Add post-fire images to post-fire map\n",
        "after_map = geemap.Map()\n",
        "\n",
        "post_size = post_mosaic_col.size().getInfo()\n",
        "post_mosaic_list = post_mosaic_col.toList(post_size)\n",
        "before_size\n",
        "\n",
        "for i in range(0,post_size):\n",
        "  b = post_mosaic_list.get(i)\n",
        "  date = b.getInfo()['properties']['system:index']\n",
        "  after_map.addLayer(ee.Image(b), vis, date)\n",
        "  print(date)\n",
        "\n",
        "# Add fire polygon\n",
        "style = {'color': 'white', 'width': 2, 'lineType': 'solid', 'fillColor': '00000000'}\n",
        "after_map.addLayer(poly.style(**style),{},'poly')\n",
        "after_map.centerObject(poly)\n",
        "after_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also take note of the post-fire image selected. If good quality post-fire imagery is not available consider changing the date range or the sensor."
      ],
      "metadata": {
        "id": "13-78_nUIcma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "i874zgNH-XtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 8: BARC mapping**"
      ],
      "metadata": {
        "id": "Kk587L-NxBIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The BARC burn severity raster raster will be created below. Change the dates for the pre_mosaic_date and post_mosaic_date variables. The BARC raster is generated by: (1) calculating pre- and post-NBR, (2) calculating dNBR by subtracting postNBR from preNBR, (3) Applying a scaling equation to dNBR and (4) Applying thresholds to create a 4-class burn severity raster (1-unburned, 2-low, 3-medium, 4-high)."
      ],
      "metadata": {
        "id": "rgGOQIyn8I2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate NBR, dNBR and generate BARC map.\n",
        "pre_mosaic_date = '2023-07-23' #enter pre-fire image date here\n",
        "post_mosaic_date = '2023-09-21' #enter post_fire image date here\n",
        "\n",
        "# Select pre-image and post-image\n",
        "pre_col = pre_mosaic_col.filter(ee.Filter.inList(\"system:index\",ee.List([pre_mosaic_date])))\n",
        "pre_img = ee.Image(pre_col.toList(1).get(0))\n",
        "\n",
        "if pre_col.size().getInfo() != 1:\n",
        "  raise ValueError(\"Didn't select 1 pre-fire image date. Check pre_mosaic_date!\")\n",
        "\n",
        "post_col = post_mosaic_col.filter(ee.Filter.inList(\"system:index\", ee.List([post_mosaic_date])))\n",
        "post_img = ee.Image(post_col.toList(1).get(0))\n",
        "\n",
        "if post_col.size().getInfo() != 1:\n",
        "  raise ValueError(\"Didn't select 1 post-fire image date. Check post_mosaic_date!\")\n",
        "\n",
        "# Calculate NBR\n",
        "if dattype.startswith('S2'):\n",
        "    pre_nbr = NBR_S2(pre_img)\n",
        "    post_nbr = NBR_S2(post_img)\n",
        "else:\n",
        "    pre_nbr = NBR_Landsat(pre_img,dattype)\n",
        "    post_nbr = NBR_Landsat(post_img,dattype)\n",
        "\n",
        "# Calculate dNBR\n",
        "dNBR = pre_nbr.subtract(post_nbr).rename('dNBR')\n",
        "\n",
        "# Scale dNBR\n",
        "dNBR_scaled = dNBR.expression('(dNBR * 1000 + 275)/5',{'dNBR': dNBR.select('dNBR')}).rename('dNBR_scaled')\n",
        "\n",
        "# Classify\n",
        "classes = dNBR_scaled.expression(\"(dNBR_scaled >= 187) ? 4 \"\n",
        "                                \": (dNBR_scaled >= 110) ? 3 \"\n",
        "                                \": (dNBR_scaled >= 76) ? 2 \"\n",
        "                                \": 1\",{'dNBR_scaled': dNBR_scaled.select('dNBR_scaled')})\n",
        "\n",
        "# Mask out water, set to 9, which will become no data\n",
        "esa_water = ee.ImageCollection('ESA/WorldCover/v200').filterBounds(poly).first().eq(80);\n",
        "\n",
        "# Clip to fire perimeter\n",
        "classes_clipped = classes.clip(poly)\n",
        "\n",
        "print(\"BARC Complete\")\n",
        "\n",
        "# Get scene ids to save\n",
        "d = ee.Date(pre_mosaic_date)\n",
        "pre_filt = before.filterDate(d,d.advance(1,'day'))\n",
        "pre_scenes_ids = pre_filt.aggregate_array('system:index').getInfo()\n",
        "print(pre_scenes_ids)\n",
        "\n",
        "d1 = ee.Date(post_mosaic_date)\n",
        "post_filt = after.filterDate(d1,d1.advance(1,'day'))\n",
        "post_scenes_ids = post_filt.aggregate_array('system:index').getInfo()\n",
        "print(post_scenes_ids)"
      ],
      "metadata": {
        "id": "Zc6E1-54L6ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iIgN0Oxo_wAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 9: Final visualization for quality control**"
      ],
      "metadata": {
        "id": "U2KwERQ-_K8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script is the final visualization of pre- and post-fire imagery as well as the BARC map. To assess the quality, toggle the layers and zoom into different regions to make sure that the pre- and post-fire imagery is free of clouds, smoke, haze or active fire."
      ],
      "metadata": {
        "id": "6eqnBdMrxKmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize pre- and post-fire imagery with BARC\n",
        "barc_map = geemap.Map()\n",
        "barc_map.addLayer(ee.Image(pre_img), vis, pre_mosaic_date)\n",
        "barc_map.addLayer(ee.Image(post_img),vis, post_mosaic_date)\n",
        "\n",
        "palette = ['000000','grey', 'yellow', 'orange','red']\n",
        "\n",
        "barc_vis = {'min':0,'max':4,'palette':palette}\n",
        "barc_map.addLayer(ee.Image(classes_clipped),barc_vis,'barc')\n",
        "\n",
        "style = {'color': 'white', 'width': 2, 'lineType': 'solid', 'fillColor': '00000000'}\n",
        "barc_map.addLayer(poly.style(**style),{},'poly')\n",
        "\n",
        "barc_map.centerObject(poly)\n",
        "barc_map"
      ],
      "metadata": {
        "id": "KFiLxtTJNs2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 10: Image download**"
      ],
      "metadata": {
        "id": "HxBSa1pHxVs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script will download a BARC raster clipped to the extent of the fire perimeter polygon, as well as pre- and post-fire imagery (true color and swir RGB, 8-bit). The search criteria and scene ids will also be exported as json and text files. The root folder will be the fire number."
      ],
      "metadata": {
        "id": "dctlR1eTi-6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export\n",
        "outfolder = firenumber #root folder\n",
        "pre_date = pre_mosaic_date\n",
        "post_date = post_mosaic_date\n",
        "\n",
        "# Define spatial resolution\n",
        "if dattype == 'S2':\n",
        "  px = 20\n",
        "else:\n",
        "  px = 30\n",
        "\n",
        "## Define tiling rules\n",
        "poly_area = round(poly.geometry().area(1).divide(10000).getInfo(),1)\n",
        "print(poly_area)\n",
        "print('Fire Area:',poly_area,'hectares')\n",
        "\n",
        "if poly_area < 10000:\n",
        "    n = 2\n",
        "elif poly_area > 10000 and poly_area < 100000:\n",
        "    n = 3\n",
        "elif poly_area > 100000 and poly_area < 400000:\n",
        "    n = 4\n",
        "else:\n",
        "    n = 5\n",
        "\n",
        "print('Number of tiles: ' + str(n*n))\n",
        "\n",
        "#export pre and post rgbs, tile to avoid pixel limit issues.\n",
        "footprint = poly.geometry().bounds().getInfo()\n",
        "grids = grid_footprint(footprint,n,n)\n",
        "\n",
        "for i in range(0,len(grids)):\n",
        "  roi = grids[i]\n",
        "  ## Export BARC\n",
        "  barc_folder = os.path.join(outfolder,'barc')\n",
        "  if not os.path.exists(barc_folder):\n",
        "          os.makedirs(barc_folder)\n",
        "\n",
        "  name = 'BARC_' + firenumber + '_' + pre_date + '_' + post_date + '_' + dattype +'_' + str(i) + '_.tif'\n",
        "  barc_filename = os.path.join(barc_folder,name)\n",
        "  geemap.ee_export_image(classes_clipped.unmask(9).clip(roi), filename=barc_filename, scale=px, file_per_band=False,crs='EPSG:3005')\n",
        "  ras = gdal.Open(barc_filename,gdal.GA_Update)\n",
        "  dat = ras.GetRasterBand(1)\n",
        "  dat.SetNoDataValue(9)\n",
        "  ras = None\n",
        "  dat = None\n",
        "\n",
        "  ## Export 8-bit truecolor images\n",
        "  #pre, truecolor\n",
        "  pre_tc_8bit = os.path.join(outfolder,'pre_truecolor_8bit')\n",
        "  if not os.path.exists(pre_tc_8bit):\n",
        "          os.makedirs(pre_tc_8bit)\n",
        "  filename = os.path.join(pre_tc_8bit, dattype + '_' + pre_date + '_truecolor_pre_8bit_' + str(i) + '.tif')\n",
        "  pre_tc_8bit_path = filename\n",
        "  if dattype.startswith('S2'):\n",
        "      viz = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max':0.3,'gamma':1.5}\n",
        "      geemap.ee_export_image(pre_img.clip(roi).visualize(**viz), filename=filename, scale=10, file_per_band=False,crs='EPSG:3005')\n",
        "  elif (dattype == 'L8') | (dattype == 'L9'):\n",
        "      viz = {'bands': ['SR_B4', 'SR_B3', 'SR_B2'], 'min': 0, 'max':0.3,'gamma':1.5}\n",
        "      geemap.ee_export_image(pre_img.clip(roi).visualize(**viz), filename=filename, scale=30, file_per_band=False,crs='EPSG:3005')\n",
        "  else:\n",
        "      pass\n",
        "\n",
        "  post_tc_8bit = os.path.join(outfolder,'post_truecolor_8bit')\n",
        "  if not os.path.exists(post_tc_8bit):\n",
        "          os.makedirs(post_tc_8bit)\n",
        "  filename = os.path.join(post_tc_8bit, dattype + '_' + post_date + '_truecolor_post_8bit_' + str(i) + '.tif')\n",
        "  post_tc_8bit_path = filename\n",
        "  if dattype.startswith('S2'):\n",
        "      viz = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max':0.3,'gamma':1.5}\n",
        "      geemap.ee_export_image(post_img.clip(roi).visualize(**viz), filename=filename, scale=10, file_per_band=False,crs='EPSG:3005')\n",
        "  elif (dattype == 'L8') | (dattype == 'L9'):\n",
        "      viz = {'bands': ['SR_B4', 'SR_B3', 'SR_B2'], 'min': 0, 'max':0.3,'gamma':1.5}\n",
        "      geemap.ee_export_image(post_img.clip(roi).visualize(**viz), filename=filename, scale=30, file_per_band=False,crs='EPSG:3005')\n",
        "  else:\n",
        "      pass\n",
        "\n",
        "  ## Export swir too\n",
        "  pre_sw_8bit = os.path.join(outfolder,'pre_swir_8bit')\n",
        "  if not os.path.exists(pre_sw_8bit):\n",
        "          os.makedirs(pre_sw_8bit)\n",
        "  filename = os.path.join(pre_sw_8bit, dattype + '_' + pre_date + '_swir_pre_8bit_' + str(i) + '.tif')\n",
        "  pre_sw_8bit_path = filename\n",
        "  if dattype.startswith('S2'):\n",
        "      viz = {'bands': ['B12', 'B8', 'B4'], 'min': 0, 'max':0.3,'gamma':1.5}\n",
        "      geemap.ee_export_image(pre_img.clip(roi).visualize(**viz), filename=filename, scale=10, file_per_band=False,crs='EPSG:3005')\n",
        "  elif (dattype == 'L8') | (dattype == 'L9'):\n",
        "      viz = {'bands': ['SR_B6', 'SR_B5', 'SR_B4'], 'min': 0, 'max':0.3,'gamma':1.5}\n",
        "      geemap.ee_export_image(pre_img.clip(roi).visualize(**viz), filename=filename, scale=30, file_per_band=False,crs='EPSG:3005')\n",
        "  else:\n",
        "      pass\n",
        "\n",
        "  post_sw_8bit = os.path.join(outfolder,'post_swir_8bit')\n",
        "  if not os.path.exists(post_sw_8bit):\n",
        "          os.makedirs(post_sw_8bit)\n",
        "  filename = os.path.join(post_sw_8bit, dattype + '_' + post_date + '_swir_post_8bit_' + str(i) + '.tif')\n",
        "  post_sw_8bit_path = filename\n",
        "  if dattype.startswith('S2'):\n",
        "      viz = {'bands': ['B12', 'B8', 'B4'], 'min': 0, 'max':0.3,'gamma':1.5}\n",
        "      geemap.ee_export_image(post_img.clip(roi).visualize(**viz), filename=filename, scale=10, file_per_band=False,crs='EPSG:3005')\n",
        "  elif (dattype == 'L8') | (dattype == 'L9'):\n",
        "      viz = {'bands': ['SR_B6', 'SR_B5', 'SR_B4'], 'min': 0, 'max':0.3,'gamma':1.5}\n",
        "      geemap.ee_export_image(post_img.clip(roi).visualize(**viz), filename=filename, scale=30, file_per_band=False,crs='EPSG:3005')\n",
        "  else:\n",
        "      pass\n",
        "\n",
        "  print(barc_folder)\n",
        "\n",
        "#mosaic all\n",
        "#BARC\n",
        "barc_list = getfiles(barc_folder,'.tif')\n",
        "outfilename = 'BARC_' + firenumber + '_' + pre_date + '_' + post_date + '_' + dattype + '.tif'\n",
        "out = os.path.join(barc_folder,outfilename)\n",
        "gdal.Warp(out,barc_list)\n",
        "for file in barc_list: os.remove(file) #delete tiles\n",
        "barc_filename = out #to return from the function\n",
        "print('Barc mosaic complete')\n",
        "\n",
        "#pre truecolour\n",
        "pre_tc_list = getfiles(pre_tc_8bit,'.tif')\n",
        "outfilename = dattype + '_' + pre_date + '_truecolor_pre_8bit' + '.tif'\n",
        "out = os.path.join(pre_tc_8bit,outfilename)\n",
        "gdal.Warp(out,pre_tc_list)\n",
        "for file in pre_tc_list: os.remove(file) #delete tiles\n",
        "pre_tc_8bit_path = out #to return from the function\n",
        "print('Pre truecolor mosaic complete')\n",
        "\n",
        "#post truecolor\n",
        "post_tc_list = getfiles(post_tc_8bit,'.tif')\n",
        "outfilename = dattype + '_' + post_date + '_truecolor_post_8bit' + '.tif'\n",
        "out = os.path.join(post_tc_8bit,outfilename)\n",
        "gdal.Warp(out,post_tc_list)\n",
        "for file in post_tc_list: os.remove(file)\n",
        "post_tc_8bit_path = out #to return from the function\n",
        "print('Post truecolor mosaic complete')\n",
        "\n",
        "#pre swir\n",
        "pre_sw_list = getfiles(pre_sw_8bit,'.tif')\n",
        "outfilename = dattype + '_' + pre_date + '_swir_pre_8bit' + '.tif'\n",
        "out = os.path.join(pre_sw_8bit,outfilename)\n",
        "gdal.Warp(out,pre_sw_list)\n",
        "for file in pre_sw_list: os.remove(file) #delete tiles\n",
        "pre_sw_8bit_path = out #to return from the function\n",
        "print('Pre swir mosaic complete')\n",
        "\n",
        "#post swir\n",
        "post_sw_list = getfiles(post_sw_8bit,'.tif')\n",
        "outfilename = dattype + '_' + post_date + '_swir_post_8bit' + '.tif'\n",
        "out = os.path.join(post_sw_8bit,outfilename)\n",
        "gdal.Warp(out,post_sw_list)\n",
        "for file in post_sw_list: os.remove(file)\n",
        "post_sw_8bit_path = out #to return from the function\n",
        "print('Post swir mosaic complete')\n",
        "\n",
        "#Export a dictionary with metadata info\n",
        "searchd = {'Id':firenumber,'sensor':dattype,\n",
        "               'cld_pre':cld_thr_pre,'pre_T1':startdate_pre,'pre_T2':enddate_pre,\n",
        "               'cld_post':cld_thr_post,'post_T1':startdate_post,'post_T2':startdate_post,\n",
        "               'pre_mosaic_date':pre_mosaic_date,'pre_scenes':pre_scenes_ids,\n",
        "               'post_mosaic_date':post_mosaic_date,'post_scenes':post_scenes_ids}\n",
        "\n",
        "params = os.path.join(outfolder,'search_params.txt')\n",
        "with open(params, 'w') as f:\n",
        "    for key, value in searchd.items():\n",
        "        f.write('%s:%s\\n' % (key, value))\n",
        "\n",
        "#write search parameters to the folder as json for use later\n",
        "output_json = os.path.join(outfolder,'search_params.json')\n",
        "with open(output_json, 'w') as json_file:\n",
        "    json.dump(searchd, json_file, indent=4)\n"
      ],
      "metadata": {
        "id": "GgAXor9eGhzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 11: Quicklooks and area burned by severity class**"
      ],
      "metadata": {
        "id": "0jGln5xDASur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script below creates and exports quicklook images, burn severity classes summaries and maps. You should be able to run as is."
      ],
      "metadata": {
        "id": "sKFCsD-XxdYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary Section\n",
        "qcdir = os.path.join(firenumber,'QC')\n",
        "if not os.path.exists(qcdir):\n",
        "  os.mkdir(qcdir)\n",
        "\n",
        "# Create powerpoint presentation\n",
        "pptpath = os.path.join(qcdir,firenumber+'.pptx')\n",
        "create_ppt(pptpath)\n",
        "\n",
        "bc_boundary ='burnSeverity/bc/BC_Boundary_Terrestrial_gcs_simplify.shp'\n",
        "\n",
        "# Pre- and post-fire quicklooks (truecolor)\n",
        "pre_tc_ql = generate_ql(outshp,pre_tc_8bit_path,qcdir)\n",
        "post_tc_ql = generate_ql(outshp,post_tc_8bit_path,qcdir)\n",
        "\n",
        "# Pre- and post-fire quicklooks (swir)\n",
        "pre_sw_ql = generate_ql(outshp,pre_sw_8bit_path,qcdir)\n",
        "post_sw_ql = generate_ql(outshp,post_sw_8bit_path,qcdir)\n",
        "\n",
        "# BARC\n",
        "name = Path(barc_filename).stem + '.png'\n",
        "barc_ql = os.path.join(qcdir,name)\n",
        "ql_barc(outshp,barc_filename,post_tc_8bit_path,barc_ql)\n",
        "\n",
        "# Location map\n",
        "name = firenumber + '_locmap.png'\n",
        "map_ql = os.path.join(qcdir,name)\n",
        "\n",
        "fire_perim = os.path.join(firenumber,'vectors',firenumber+'_gcs.shp')\n",
        "if os.path.isfile(fire_perim):\n",
        "    pass\n",
        "else:\n",
        "    fire_perim = os.path.join(firenumber,'vectors',firenumber+'.shp')\n",
        "\n",
        "inset_map(bc_boundary,fire_perim,map_ql)\n",
        "\n",
        "#add stats table\n",
        "outpath = os.path.join(qcdir,'barc_stats.csv')\n",
        "df = zonal_barc(barc_filename,outshp,outpath)\n",
        "\n",
        "#Add slide to powerpoint\n",
        "add_slide(pptpath,pre_tc_ql,post_tc_ql,barc_ql,map_ql,df)\n",
        "add_slide(pptpath,pre_sw_ql,post_sw_ql,barc_ql,map_ql,df)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qkan1YWqcPAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RoiuiHO_AlXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 12: Final export**"
      ],
      "metadata": {
        "id": "oc_DkA_8A6tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The folder will be zipped and saved under the Files tab. Right click and download the folder to your machine."
      ],
      "metadata": {
        "id": "-An_hMo3qPI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Zip to download\n",
        "zip = firenumber + '.zip'\n",
        "indata = firenumber\n",
        "\n",
        "!zip -r {zip} {indata}\n",
        "files.download(zip)"
      ],
      "metadata": {
        "id": "sdt_TRppUAVu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LTi0frCUCpkW"
      ],
      "authorship_tag": "ABX9TyMUh7CBEFurYARDRk+5Y1aw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}